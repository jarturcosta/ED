{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction via\n",
    "      Principal Component Analysis (PCA)\n",
    "      Kernel Principal Component Analysis (KPCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main goal is to project the data onto the most relevant directions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigendecomposition of the covariance matrix allows to find out the directions where the data has the largest spread.\n",
    "\n",
    "     the eigenvectors are related with these directions\n",
    "     the eigenvalues are related with the spread of the data on the directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "# graphics and maths\n",
    "#Numerical python functions written for compatability with MATLAB commands with the same names.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec \n",
    "import matplotlib.mlab as mlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Half-moon shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "Xtoy, ytoy = make_moons(n_samples=100, random_state=123)\n",
    "\n",
    "plt.scatter(Xtoy[ytoy == 0, 0], Xtoy[ytoy == 0, 1], color='red', marker='^', alpha=0.5)\n",
    "plt.scatter(Xtoy[ytoy == 1, 0], Xtoy[ytoy == 1, 1], color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/half_moon_1.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d431c379e5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_spca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtoy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_spca = pca.fit_transform(Xtoy)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 3))\n",
    "\n",
    "ax[0].scatter(X_spca[ytoy == 0, 0], X_spca[ytoy == 0, 1],\n",
    "              color='red', marker='^', alpha=0.5)\n",
    "ax[0].scatter(X_spca[ytoy == 1, 0], X_spca[ytoy == 1, 1],\n",
    "              color='blue', marker='o', alpha=0.5)\n",
    "inx=sum(ytoy==0)\n",
    "print(inx)\n",
    "ax[1].scatter(X_spca[ytoy == 0, 0], np.zeros((inx, 1)) + 0.02,\n",
    "              color='red', marker='^', alpha=0.5)\n",
    "inx=sum(ytoy==0)\n",
    "print(inx)\n",
    "ax[1].scatter(X_spca[ytoy == 1, 0], np.zeros((inx, 1)) - 0.02,\n",
    "              color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "ax[0].set_xlabel('PC1')\n",
    "ax[0].set_ylabel('PC2')\n",
    "ax[1].set_ylim([-1, 1])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xlabel('PC1')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/half_moon_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. Interpret the code. what is represented on the figures.\n",
    "2. Reducing the dimension to one. With this projection is possible to discriminate between blue and red examples?\n",
    "3. What are the directions to project the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "#print(Xtoy[0:2,:])\n",
    "#print(X_spca[0:2,:])\n",
    "#print(X_spca.shape)\n",
    "#aa=pca.inverse_transform(X_spca[0:2,:])\n",
    "#print(aa)\n",
    "# The eigenvectors\n",
    "print('eigenvectors\\n', pca.components_)\n",
    "# singular values\n",
    "print('singular_ values\\n', pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf', gamma=15)\n",
    "X_spca = kpca.fit_transform(Xtoy)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 3))\n",
    "\n",
    "ax[0].scatter(X_spca[ytoy == 0, 0], X_spca[ytoy == 0, 1],\n",
    "              color='red', marker='^', alpha=0.5)\n",
    "ax[0].scatter(X_spca[ytoy == 1, 0], X_spca[ytoy == 1, 1],\n",
    "              color='blue', marker='o', alpha=0.5)\n",
    "inx=sum(ytoy==0)\n",
    "print(inx)\n",
    "ax[1].scatter(X_spca[ytoy == 0, 0], np.zeros((inx, 1)) ,\n",
    "              color='red', marker='^', alpha=0.5)\n",
    "inx=sum(ytoy==0)\n",
    "print(inx)\n",
    "ax[1].scatter(X_spca[ytoy == 1, 0], np.zeros((inx, 1)),\n",
    "              color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "ax[0].set_xlabel('PC1')\n",
    "ax[0].set_ylabel('PC2')\n",
    "ax[1].set_ylim([-1, 1])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xlabel('PC1')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/circles_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "1.  Interpret the results.\n",
    "2.  Which kernel was used?\n",
    "3.  Reducing the dimension to one. With this projection is possible to discriminate between blue and red examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Separating concentric circles\n",
    "\n",
    "Try PCA and Kernel PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "Xtoy1, ytoy1 = make_circles(n_samples=1000, random_state=123, noise=0.1, factor=0.2)\n",
    "\n",
    "plt.scatter(Xtoy[ytoy == 0, 0], Xtoy[ytoy == 0, 1], color='red', marker='^', alpha=0.5)\n",
    "plt.scatter(Xtoy[ytoy == 1, 0], Xtoy[ytoy == 1, 1], color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/circles_1.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3:\n",
    "1. Reading a data set.\n",
    "2. Two  processing blocks  before the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wdbcBBB.csv\",header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID',axis=1,inplace=True)\n",
    "print(df.diagnosis.unique())\n",
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=df.as_matrix(columns=[df.columns[0]])\n",
    "\n",
    "# features\n",
    "X=df.as_matrix(columns=df.columns[1:])\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data : zero mean an variance one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:\n",
    "Interpret the procedure to standardize the data.\n",
    "\n",
    "\n",
    "**Comment**\n",
    " the correct way is to re-use parameters from the training set if we are doing any kind of transformation -- the test set should basically stand for \"new, unseen\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(30), pca.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "plt.step(range(30), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction before classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only two components for illustration\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "print(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "1. With two components what is the explained variance kept by two projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Explain data manipulations in train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "axes = axes.ravel()   \n",
    "ax = axes[0]\n",
    "ax.figure\n",
    "inx=(y_train==1)\n",
    "inx=inx.ravel()\n",
    "ax.scatter(X_train_pca[inx,0],X_train_pca[inx,1],marker='s',color='r',label='M')  \n",
    "\n",
    "inx=(y_train==0)\n",
    "inx=inx.ravel()\n",
    "ax.scatter(X_train_pca[inx,0],X_train_pca[inx,1],marker='o',color='g',label='B')    \n",
    "ax.set_title(\"Training set\")\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "#plt.show()\n",
    " \n",
    "\n",
    "ax = axes[1]\n",
    "ax.figure\n",
    "inx=(y_test==1)\n",
    "inx=inx.ravel()\n",
    "ax.scatter(X_test_pca[inx,0],X_test_pca[inx,1],marker='s',color='r',label='M')  \n",
    "inx=(y_test==0)\n",
    "inx=inx.ravel()\n",
    "ax.scatter(X_test_pca[inx,0],X_test_pca[inx,1],marker='o',color='g',label='B')\n",
    "    \n",
    "ax.set_title(\"Test set: data not used to adapt PCA\")    \n",
    "\n",
    "ax.legend() \n",
    "ax.grid()\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "A classififier  with the Principal components of the data.\n",
    "\n",
    "1. How many atributes are in the input of the classifier?\n",
    "\n",
    "2. How the attributes can be related with the raw data?\n",
    "\n",
    "3. Try to use a Kernel PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
